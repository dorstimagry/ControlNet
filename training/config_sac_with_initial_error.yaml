# Configuration for SAC training with pretrained SysID encoder
# 
# This config loads a pretrained SysID encoder and freezes it during SAC training.
# The encoder provides vehicle-specific dynamics features to the policy/critic.
#
# Usage:
#   1. First pretrain SysID:
#      python scripts/pretrain_sysid.py --config training/config_sysid.yaml --num-steps 50000
#   2. Then train SAC with this config:
#      python training/train_sac.py --config training/config_sac_pretrained.yaml

# Context mode selection
context_mode: "none"  # Options: "none", "sysid", "dynamics_map"

env:
  # Action space bounds (dimensionless, -1 to 1)
  action_high: 1.0          # Maximum action value (full throttle/brake)
  action_low: -1.0          # Minimum action value (full brake)

  # Reward function weights (dimensionless, affect reward scaling)
  accel_filter_alpha: 0.2   # Exponential smoothing factor for acceleration (0=no smoothing, 1=instant)
  action_weight: 4000.0       # Penalty weight for action magnitude (reduces aggressive control)
  brake_weight: 0.0         # Penalty weight for brake usage (set to 0 to disable)
  negative_speed_weight: 1000.0   # Penalty weight for negative vehicle speeds (prevents reverse)
  zero_speed_error_weight: 1000.0    # Penalty for speed error when target speed is 0
  zero_speed_throttle_weight: 1000.0 # Penalty for throttle usage when target speed is 0
  horizon_penalty_weight: 0.0  # Weight for future horizon tracking penalties
  horizon_penalty_decay: 0.99  # Exponential decay factor for future penalties (0.9-1.0)
  jerk_weight: 4500.0          # Penalty weight for acceleration changes (smoothness)
  smooth_action_weight: 25000.0 # Penalty weight for action changes (stability)
  track_weight: 15000.0         # Weight for speed tracking error in reward
  
  # Sliding-window mean speed error penalty (bias elimination)
  # See docs/accumulated_error.md for details
  bias_penalty_enabled: false  # Enable sliding-window mean error penalty
  bias_penalty_window_s: 2.0  # Window length in seconds (T_window, recommended: 1-3 s)
  bias_penalty_weight: 2000.0  # Weight for bias penalty (w_bias, recommended: 0.3 × track_weight = 0.3 × 1500)
  bias_penalty_v_scale: 15.0  # Speed scale for normalization (typical operating speed)
  bias_penalty_v_ref_dot_threshold: 0.3  # Reference speed change threshold for gating (m/s², recommended: 0.1-0.3)
  bias_penalty_a_threshold: 0.5  # Vehicle acceleration threshold for gating (m/s², recommended: 0.2-0.5)
  
  # Maximum absolute acceleration and jerk penalties (H-infinity norm)
  max_acc_penalty_weight: 35.0  # Weight for maximum absolute acceleration penalty (only when |acc| > |target_acc|)
  max_jerk_penalty_weight: 15.0  # Weight for maximum absolute jerk penalty (only when |jerk| > |target_jerk|)
  
  # Oscillation and overshoot penalty configuration
  # See docs/oscillation_and_overshoot_penalties_for_rl_longitudinal_control.md for details
  oscillation_weight: 20000.0  # Weight for oscillatory switching penalty (λ_osc) - start small (1-5% of track_weight)
  overshoot_weight: 0.0  # Weight for overshoot crossing penalty (λ_over) - typically 0.1-0.3 × oscillation_weight
  oscillation_epsilon: 0.05  # Smoothing parameter for action sign (ε) - typical range: 0.03-0.08
  oscillation_error_scale: 0.3  # Error scale for proximity gate (e_s in m/s) - typical range: 0.2-0.5
  oscillation_ref_scale: 0.3  # Reference rate scale for stationarity gate (r_s in m/s²) - typical range: 0.2-0.5
  overshoot_crossing_scale: 0.02  # Crossing detection scale (c_s) - typical range: 0.01-0.05
  
  # Comfort penalty annealing - gradually increase comfort penalties during training
  # This allows the agent to first learn tracking, then refine for smoothness
  comfort_anneal_enabled: false   # Enable/disable comfort penalty annealing
  comfort_anneal_start_mult: 0.5  # Multiplier at training start (0 = no comfort penalty)
  comfort_anneal_end_mult: 1.0    # Multiplier at end of annealing (1 = full comfort penalty)
  comfort_anneal_steps: 100000    # Number of steps to anneal over (linear interpolation)
  voltage_weight: 0.0       # Penalty weight for motor voltage (set to 0 to disable)

  # Simulation parameters
  dt: 0.1                   # Policy step time (seconds) - controls control frequency
  max_episode_steps: 256   # Maximum steps per episode (affects episode length)
  max_position: 5000.0      # Maximum position before episode termination (meters)
  max_speed: 25.0           # Maximum allowed speed (m/s) - affects reward clipping
  plant_substeps: 5         # Physics simulation substeps per policy step (stability)
  preview_horizon_s: 3.0    # How far ahead the agent can see reference speeds (seconds)
  use_extended_plant: true  # Use detailed vehicle dynamics model (true) or simple (false)
  
  # Violent profile training mode configuration
  violent_profile_mode: false  # Enable/disable violent profile mode (non-smooth profiles in observations)
  filter_reward_mode: false  # Enable/disable filter reward mode (standard profiles in observations, filtered profiles for reward)
  reward_filter_use_lookahead: false  # Enable/disable look-ahead mode for reward filter
  reward_filter_lookahead_s: 3.0  # Look-ahead time for reward filter (seconds, must be <= preview_horizon_s)
  reward_filter_freq_cutoff: 0.8  # Filter cutoff frequency for reward (Hz)
  reward_filter_zeta: 4.0  # Filter damping ratio for reward
  reward_filter_dt: 0.1  # Filter timestep for reward (should match env dt)
  reward_filter_rate_max: 1.5  # Default max acceleration for reward filter (m/s²) - overridden per episode based on vehicle
  reward_filter_rate_neg_max: 1.5  # Default max deceleration for reward filter (m/s²) - overridden per episode based on vehicle
  reward_filter_jerk_max: 0.5  # Default max jerk for reward filter (m/s³)
  
  # Initial speed randomization
  initial_speed_error_range: 5.0  # Maximum absolute error for random initial speed (m/s). When > 0, initial speed is sampled from [reference[0] - error_range, reference[0] + error_range]. 0.0 = disabled (use reference[0])
  
  # Initial action randomization
  randomize_initial_action: true  # If True, initialize the first previous action to a random value in [action_low, action_high]. If False, initialize to 0.0.
output:
  dir: training/checkpoints_sac_with_initial_error     # Directory to save model checkpoints
  save_latest: true             # Whether to save the latest checkpoint during training
reference_dataset: null         # Path to reference dataset (null = use generator)
seed: 42                        # Random seed for reproducibility
training:
  # SAC algorithm hyperparameters
  gamma: 0.95                # Discount factor for future rewards (0.9-0.99)
  learning_rate: 0.0003      # Learning rate for policy/critic updates
  tau: 0.01                  # Soft update coefficient for target networks (0.001-0.01)
  target_entropy_scale: 0.98 # Target entropy scaling for automatic temperature tuning

  # Training schedule
  num_train_timesteps: 1000000  # Total training steps (environment interactions)
  warmup_steps: 10000         # Steps before training starts (random exploration)
  batch_size: 4096             # Minibatch size for training updates
  replay_size: 1000000        # Maximum replay buffer size (steps)

  # Logging and checkpointing
  log_interval: 1000          # Steps between logging training metrics
  checkpoint_interval: 10000  # Steps between saving model checkpoints
  max_grad_norm: 5.0          # Maximum gradient norm for clipping (stability)

  # Evaluation during training
  eval_interval: 5000         # Steps between evaluation runs during training
  eval_episodes: 5            # Number of episodes per evaluation run
  
  # Online animation (optional)
  enable_animation: true     # Enable online animation showing policy performance on fixed episode
  animation_interval: 5000    # Steps between animation updates (default: same as eval_interval)
  num_animation_episodes: 3   # Number of example episodes to show (each with different initial speed error)

  # Action planning (for MPC-style policies, if used)
  action_horizon_steps: 1    # Planning horizon for action sequences (steps)

# ========================================================================
# SysID Configuration: Load pretrained encoder, freeze during SAC training
# ========================================================================
sysid:
  enabled: false
  
  # IMPORTANT: Path to pretrained SysID checkpoint
  pretrained_path: "training/sysid_pretrained/sysid_best.pt"
  
  # IMPORTANT: Freeze encoder during SAC training (recommended)
  # Set to false to fine-tune encoder alongside SAC
  freeze_encoder: true
  
  # Architecture (must match pretrained model)
  dz: 12
  gru_hidden: 64
  predictor_hidden: 128
  predictor_layers: 2
  
  # Training windows (must match pretrained model)
  burn_in: 20
  horizon: 40
  
  # Loss weights (only used if freeze_encoder: false)
  lambda_slow: 0.005
  lambda_z: 0.0005
  
  # Optimization (only used if freeze_encoder: false)
  learning_rate: 0.001
  update_every: 1
  updates_per_step: 1
  pretrain_steps: 0
  
  # Normalization
  norm_clip: 10.0
  norm_eps: 1.0e-6

generator:
  # Low-Pass Filter (LPF) parameters for smoothing target speed profiles
  freq_cutoff: 0.8         # LPF cutoff frequency (Hz) - higher = more responsive but less smooth
  zeta: 4.0                # Damping ratio - higher = more stable but slower response
  dt: 0.02                 # LPF internal timestep (seconds) - affects smoothness resolution
  jerk_max: 0.5            # Maximum allowed jerk (m/s³) - limits acceleration changes
  rate_max_limit: 1.5     # Maximum acceleration limit for LPF (m/s²) - clamps vehicle-based acceleration
  rate_neg_max_limit: 1.5 # Maximum deceleration limit for LPF (m/s²) - clamps vehicle-based deceleration
  lpf_safety_factor: 0.85  # Safety factor applied to vehicle-based acceleration limits (0.0-1.0) - lower = more conservative

  # Event-driven target generation parameters
  p_change: 0.03           # Probability of changing target speed per step (0-1)
  p_zero_stop: 0.08        # Probability of sampling full stops vs. speed targets (0-1)
  v_min: 0.0               # Minimum speed for random targets (m/s)
  v_max_sample: 25.0       # Maximum speed for random targets (m/s)
  speed_beta: 3.0          # Beta distribution parameter for speed sampling (higher = more small speeds, 1.0 = uniform)
  t_min: 2.0               # Minimum time to reach new target (seconds)
  t_max: 12.0              # Maximum time to reach new target (seconds)
  stop_hold_min: 1.0       # Minimum dwell time for full stops (seconds)
  stop_hold_max: 5.0       # Maximum dwell time for full stops (seconds)

  # Stochastic acceleration/jerk sampling parameters
  p_change_acc: 0.01       # Probability of changing acceleration scale per step (0-1)
  p_change_jerk: 0.01      # Probability of changing jerk scale per step (0-1)
  p_zero_accel: 0.15        # Probability of sampling zero acceleration when acceleration changes
  accel_beta: 3.0          # Beta distribution parameter (higher = more small accelerations)

  # Road grade generation parameters (Ornstein-Uhlenbeck process)
  ds: 1.0                  # Spatial grid step size (meters) - resolution of grade map
  l_corr: 300.0             # Spatial correlation length (meters) - road segment smoothness
  sigma_g_stat: 0.02      # Grade standard deviation (radians) - ~0.29° typical variation
  g_min: -0.08             # Minimum grade angle (radians) - ~ -4.6° max downhill
  g_max: 0.08              # Maximum grade angle (radians) - ~ +4.6° max uphill

  # Speed limit safety factor
  speed_limit_safety_factor: 0.8  # Multiplier for max feasible speed (0.75 = 25% reduction from theoretical max)

vehicle_randomization:
  Fitted vehicle mode (optional): use fitted params as center of randomization
  mode: "fitted"                        # "default" for standard ranges, "fitted" for centered
  fitted_params_path: "data/processed/NiroEV/NIROEV_HA_02/fitted_params.json"              # Path to fitted_params.json (e.g., "data/processed/NiroEV/NIROEV_HA_02/fitted_params.json")
  spread_pct: 0.05                       # Spread around fitted mean (0.1 = ±10%)
  
  # Basic vehicle parameters (per new_params_randomization.md)
  mass_range: [1500.0, 6000.0]          # kg - vehicle mass range
  rolling_coeff_range: [0.007, 0.015]   # C_rr - rolling resistance coefficient
  drag_area_range: [0.2, 0.8]           # CdA (m²) - drag coefficient * frontal area
  actuator_tau_range: [0.05, 0.30]      # seconds - actuator time constant
  grade_range_deg: [-5.7, 5.7]          # degrees - ±10% road grade range

  # Motor electrical parameters (use log-uniform in code for R, L, K, b, J)
  motor_Vmax_range: [200.0, 800.0]      # V - motor max voltage
  motor_R_range: [0.02, 0.6]            # Ω - armature resistance
  motor_L_range: [0.0001, 0.01]         # H - armature inductance
  motor_K_range: [0.05, 0.4]            # Nm/A (K_t = K_e in SI)
  motor_b_range: [0.000001, 0.005]      # Nm·s/rad - viscous damping
  motor_J_range: [0.0001, 0.01]         # kg·m² - rotor inertia

  # Gearbox
  gear_ratio_range: [4.0, 20.0]         # gear reduction ratio
  eta_gb_range: [0.85, 0.98]            # gearbox efficiency

  # Brake parameters (per new_params_randomization.md)
  brake_tau_range: [0.04, 0.12]        # seconds - brake time constant
  brake_accel_range: [8.0, 11.0]       # m/s² - max braking deceleration
  brake_p_range: [1.0, 1.8]            # brake pressure exponent
  brake_kappa_range: [0.02, 0.25]      # brake slip smoothing constant

  # Wheel parameters
  wheel_radius_range: [0.26, 0.38]     # m - wheel radius (typical passenger vehicles)
  wheel_inertia_range: [0.5, 5.0]      # kg·m² - wheel + rotating assembly inertia

  # Friction
  mu_range: [0.7, 1.0]                 # tire-road friction coefficient
  
  # Feasibility thresholds (for rejection sampling)
  min_accel_from_rest: 2.5             # m/s² - minimum acceleration at standstill
  min_brake_decel: 4.0                 # m/s² - minimum braking deceleration
  min_top_speed: 20.0                  # m/s - minimum achievable top speed
